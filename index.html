<!doctype html>
<html lang="de">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover" />
<title>TBFL_6 ‚Äî Web Audio Visualizer</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>

<style>
  * { margin:0; padding:0; box-sizing:border-box; }
  html,body { 
    height:100%; 
    background:#000000; 
    color:#00FF00; 
    font-family: 'Courier New', monospace; 
    overflow:hidden; 
  }
  
  #ui {
    position: absolute; 
    left:20px; 
    top:20px; 
    z-index: 10;
    background: rgba(0,0,0,0.8); 
    border:2px solid #00FF00; 
    padding:15px; 
    border-radius:0px;
    min-width:280px;
  }
  
  #title { 
    font-weight:bold; 
    font-size:16px; 
    color:#00FF00; 
    margin-bottom:12px;
    letter-spacing: 2px;
  }
  
  .section {
    margin-bottom:10px;
    padding:8px 0;
    border-top:1px solid #003300;
  }
  
  .section:first-of-type {
    border-top:none;
  }
  
  .label {
    font-size:11px;
    color:#00FF00;
    margin-bottom:6px;
    opacity:0.8;
  }
  
  button, label.file-label { 
    color:#00FF00; 
    background:#000000; 
    border:1px solid #00FF00; 
    padding:8px 12px; 
    margin:2px 0;
    cursor:pointer; 
    font-family: 'Courier New', monospace; 
    font-size:11px;
    width:100%;
    text-align:left;
    transition: all 0.1s;
  }
  
  button:hover, label.file-label:hover { 
    background:#003300;
    box-shadow: 0 0 8px rgba(0,255,0,0.4);
  }
  
  button:active, label.file-label:active { 
    background:#001100;
  }
  
  input[type=file] { display:none; }
  
  #status { 
    font-size:10px; 
    color:#00FF00; 
    margin-top:12px; 
    padding:8px; 
    background:rgba(0,50,0,0.3); 
    border:1px solid #003300;
    min-height:40px;
    line-height:1.4;
  }
  
  .error { color:#FF0000 !important; background:rgba(50,0,0,0.3) !important; }
  .success { color:#00FF00 !important; }
  
  canvas { display:block; }
  
  #coords {
    position: absolute;
    bottom: 20px;
    left: 20px;
    background: rgba(0,0,0,0.8);
    border: 1px solid #00FF00;
    padding: 10px;
    font-size: 9px;
    color: #00FF00;
    font-family: 'Courier New', monospace;
    max-height: 200px;
    overflow-y: auto;
    min-width: 200px;
  }
  
  .coord-line {
    margin: 2px 0;
    opacity: 0.8;
  }
</style>
</head>

<body>

<div id="ui">
  <div id="title">TBFL_6</div>
  
  <div class="section">
    <div class="label">üîä Eingabequelle w√§hlen:</div>
    <button id="btn-mic">üé§ [1] Mikrofon (Live)</button>
    <label for="wavfile" class="file-label">üéµ [2] WAV-Datei analysieren</label>
    <input id="wavfile" type="file" accept=".wav,.mp3,audio/*" />
  </div>
  
  <div class="section">
    <button id="btn-stop">‚èπ Stop</button>
  </div>
  
  <div id="status">Bereit. Bitte Eingabequelle w√§hlen.</div>
</div>

<div id="coords"></div>

<script>
console.log("üéµ TBFL_6 Visualizer wird initialisiert...");

// ================================
// PARAMETER (wie Python-Script)
// ================================
const DURATION = 0.1;
const NOISE_THRESHOLD = 0.01;
const MAX_POINTS = Math.floor(2 / DURATION);
const FFT_SIZE = 2048;

let audioCtx = null;
let analyser = null;
let sourceNode = null;
let running = false;
let audioSource = null;

const frequencies = [];
const loudness = [];
const centroids = [];

// iOS Audio Fix
document.addEventListener("touchstart", () => {
  if (audioCtx && audioCtx.state === "suspended") {
    audioCtx.resume();
  }
}, { once: true });

// ================================
// THREE.JS SETUP - EXAKT WIE PYTHON
// ================================
const scene = new THREE.Scene();
scene.background = new THREE.Color(0x000000);

const camera = new THREE.PerspectiveCamera(45, innerWidth/innerHeight, 0.1, 10000);
camera.position.set(0, 800, 1500);

const renderer = new THREE.WebGLRenderer({antialias:false, alpha:false});
renderer.setPixelRatio(1);
renderer.setSize(innerWidth, innerHeight);
document.body.appendChild(renderer.domElement);

// Grid wie Python (blasses Wei√ü, sehr transparent)
const gridSize = 4000;
const gridDivisions = 40;
const gridHelper = new THREE.GridHelper(gridSize, gridDivisions, 0xFFFFFF, 0xFFFFFF);
gridHelper.material.opacity = 0.05;
gridHelper.material.transparent = true;
gridHelper.material.depthWrite = false;
scene.add(gridHelper);

// Achsen unsichtbar machen
scene.add(new THREE.AxesHelper(0));

// ================================
// GEOMETRIE - Quadratische Marker wie Python
// ================================
const maxCapacity = MAX_POINTS;
const positions = new Float32Array(maxCapacity * 3);
const colors = new Float32Array(maxCapacity * 4);
const sizes = new Float32Array(maxCapacity);

const geometry = new THREE.BufferGeometry();
geometry.setAttribute("position", new THREE.BufferAttribute(positions, 3));
geometry.setAttribute("color", new THREE.BufferAttribute(colors, 4));
geometry.setAttribute("size", new THREE.BufferAttribute(sizes, 1));

// Quadratisches Punkt-Material (wie Python marker="s")
const material = new THREE.ShaderMaterial({
  vertexColors: true,
  transparent: true,
  depthTest: true,
  vertexShader: `
    attribute float size;
    attribute vec4 color;
    varying vec4 vColor;
    void main(){
      vColor = color;
      vec4 mvPosition = modelViewMatrix * vec4(position, 1.0);
      gl_Position = projectionMatrix * mvPosition;
      gl_PointSize = size * (300.0 / -mvPosition.z);
    }
  `,
  fragmentShader: `
    varying vec4 vColor;
    void main(){
      // Quadratische Form
      vec2 coord = gl_PointCoord - vec2(0.5);
      if(abs(coord.x) > 0.45 || abs(coord.y) > 0.45) discard;
      gl_FragColor = vColor;
    }
  `
});

const points = new THREE.Points(geometry, material);
scene.add(points);

// Linien zwischen Punkten
const linePositions = new Float32Array((maxCapacity - 1) * 2 * 3);
const lineColors = new Float32Array((maxCapacity - 1) * 2 * 4);
const lineGeom = new THREE.BufferGeometry();
lineGeom.setAttribute("position", new THREE.BufferAttribute(linePositions, 3));
lineGeom.setAttribute("color", new THREE.BufferAttribute(lineColors, 4));

const lineMat = new THREE.LineBasicMaterial({ 
  vertexColors: true, 
  transparent: true,
  linewidth: 1
});
const lines = new THREE.LineSegments(lineGeom, lineMat);
scene.add(lines);

// ================================
// SMOOTH AXIS SCALING (wie Python)
// ================================
let x_min = 0, x_max = 1000;
let y_min = 0, y_max = 2000;
let z_min = 0, z_max = 1;
const SMOOTH_FACTOR = 0.3;

// ================================
// HELPER FUNCTIONS
// ================================
function updateStatus(msg, type = 'normal'){
  const status = document.getElementById('status');
  status.textContent = msg;
  status.className = type;
  console.log(`[${type}] ${msg}`);
}

function computeRMS(arr){
  let s=0;
  for(let i=0;i<arr.length;i++) s+=arr[i]*arr[i];
  return Math.sqrt(s/arr.length);
}

function computeCentroid(mags, freqs){
  let num=0, den=0;
  for(let i=0;i<mags.length;i++){
    num += mags[i] * freqs[i];
    den += mags[i];
  }
  return den>0 ? num/den : 0;
}

function findDominantFreq(mags, freqs){
  let maxIdx = 0;
  let maxVal = -Infinity;
  for(let i=0;i<mags.length;i++){
    if(mags[i] > maxVal){ 
      maxVal=mags[i]; 
      maxIdx=i; 
    }
  }
  return freqs[maxIdx] || 0;
}

function analyzeAudio(){
  if(!analyser || !running) return;
  
  const timeData = new Float32Array(analyser.fftSize);
  analyser.getFloatTimeDomainData(timeData);
  const rms = computeRMS(timeData);
  
  if(rms < NOISE_THRESHOLD) return;
  
  const freqBinCount = analyser.frequencyBinCount;
  const freqDb = new Float32Array(freqBinCount);
  analyser.getFloatFrequencyData(freqDb);
  
  const mags = new Float32Array(freqBinCount);
  const binFreqs = new Float32Array(freqBinCount);
  const nyquist = audioCtx.sampleRate / 2;
  
  for(let i=0; i<freqBinCount; i++){
    mags[i] = Math.pow(10, freqDb[i]/20);
    binFreqs[i] = (i/freqBinCount) * nyquist;
  }
  
  const dominant = findDominantFreq(mags, binFreqs);
  const centroid = computeCentroid(mags, binFreqs);
  
  // Wie Python: deque mit maxlen
  if(frequencies.length >= MAX_POINTS){
    frequencies.shift();
    loudness.shift();
    centroids.shift();
  }
  
  frequencies.push(dominant);
  loudness.push(rms);
  centroids.push(centroid);
}

// ================================
// AUDIO START (MIC)
// ================================
async function startMic() {
  if (running) {
    updateStatus("Audio l√§uft bereits...", "error");
    return;
  }

  updateStatus("üé§ Mikrofon wird gestartet...", "normal");
  console.log("üé§ Mikrofon-Zugriff wird angefordert...");

  try {
    if (!audioCtx) {
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      console.log("‚úì AudioContext erstellt");
    }

    if (audioCtx.state === "suspended") {
      await audioCtx.resume();
    }

    const stream = await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: false,
        noiseSuppression: false,
        autoGainControl: false
      }
    });
    console.log("‚úì Mikrofon-Zugriff gew√§hrt");

    sourceNode = audioCtx.createMediaStreamSource(stream);
    analyser = audioCtx.createAnalyser();
    analyser.fftSize = FFT_SIZE;
    analyser.smoothingTimeConstant = 0.8;

    sourceNode.connect(analyser);
    running = true;
    audioSource = stream;

    updateStatus("üéôÔ∏è Aufnahme/Analyse l√§uft...", "success");
    console.log("‚úì Mikrofon aktiv");

  } catch (err) {
    console.error("‚ùå Mikrofon-Fehler:", err);
    let errorMsg = "‚ùå Mikrofon-Fehler: ";
    if (err.name === "NotAllowedError") {
      errorMsg += "Zugriff verweigert.";
    } else if (err.name === "NotFoundError") {
      errorMsg += "Kein Mikrofon gefunden.";
    } else {
      errorMsg += err.message;
    }
    updateStatus(errorMsg, "error");
  }
}

// ================================
// AUDIO: FILE
// ================================
async function startFile(file){
  console.log("üéµ WAV-Datei geladen:", file.name);
  
  if (running) stopAll();

  updateStatus(`üéµ Lade ${file.name}...`, "normal");

  try {
    if (!audioCtx) {
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    }

    const buf = await file.arrayBuffer();
    const decoded = await audioCtx.decodeAudioData(buf);
    console.log(`‚úì Audio dekodiert: ${decoded.duration.toFixed(2)}s`);

    const bs = audioCtx.createBufferSource();
    bs.buffer = decoded;

    analyser = audioCtx.createAnalyser();
    analyser.fftSize = FFT_SIZE;
    analyser.smoothingTimeConstant = 0.8;

    bs.connect(analyser);
    analyser.connect(audioCtx.destination);

    bs.start();
    running = true;
    audioSource = bs;

    updateStatus(`üéôÔ∏è Aufnahme/Analyse l√§uft... (${file.name})`, "success");

    bs.onended = () => {
      running = false;
      updateStatus("‚èπÔ∏è Beendet", "normal");
      console.log("‚èπÔ∏è Wiedergabe beendet");
    };

  } catch(err) {
    console.error("‚ùå Datei-Fehler:", err);
    updateStatus("‚ùå Fehler beim Laden: " + err.message, "error");
  }
}

// ================================
// STOP AUDIO
// ================================
function stopAll(){
  console.log("‚èπÔ∏è Beendet durch Benutzer");
  running = false;
  
  if(audioSource && audioSource.getTracks){
    audioSource.getTracks().forEach(track => track.stop());
  }
  
  if(audioSource && audioSource.stop){
    try{ audioSource.stop(); }catch(e){}
  }
  
  try{ 
    if(sourceNode) sourceNode.disconnect(); 
    if(analyser) analyser.disconnect();
  }catch(e){}
  
  analyser = sourceNode = audioSource = null;
  frequencies.length = 0;
  loudness.length = 0;
  centroids.length = 0;
  
  updateStatus("üîá Stream beendet.", "normal");
}

// ================================
// UI EVENTS
// ================================
document.getElementById("btn-mic").onclick = () => {
  startMic().catch(err => console.error(err));
};

document.getElementById("btn-stop").onclick = stopAll;

document.getElementById("wavfile").addEventListener("change", e => {
  if (e.target.files[0]) {
    startFile(e.target.files[0]);
  }
  e.target.value = '';
});

// ================================
// KOORDINATEN ANZEIGEN (wie Python)
// ================================
function updateCoordinates(){
  const coordsDiv = document.getElementById('coords');
  if(frequencies.length === 0){
    coordsDiv.innerHTML = '<div style="opacity:0.5">Keine Daten</div>';
    return;
  }
  
  let html = '';
  const n = Math.min(frequencies.length, 10); // Letzte 10 Punkte
  for(let i = frequencies.length - n; i < frequencies.length; i++){
    const age = i / Math.max(1, frequencies.length-1);
    const opacity = 0.3 + age * 0.7;
    html += `<div class="coord-line" style="opacity:${opacity}">` +
            `(${frequencies[i].toFixed(0)}, ${centroids[i].toFixed(0)}, ${loudness[i].toFixed(2)})` +
            `</div>`;
  }
  coordsDiv.innerHTML = html;
}

// ================================
// ANIMATION LOOP - EXAKT WIE PYTHON
// ================================
let rotation_angle = 0;
let lastTime = performance.now();

function animate(t){
  requestAnimationFrame(animate);
  
  const dt = (t - lastTime) / 1000;
  lastTime = t;
  
  // Audio-Analyse
  if(running){
    analyzeAudio();
  }
  
  // Rotation wie Python (elev=20, azim rotierend)
  rotation_angle += 0.3;
  const rad = rotation_angle * Math.PI / 180;
  const radius = 1500;
  camera.position.x = Math.sin(rad) * radius;
  camera.position.z = Math.cos(rad) * radius;
  camera.position.y = 800;
  camera.lookAt(0, 0, 0);
  
  const n = frequencies.length;
  
  if(n > 1){
    // Smooth Axis Rescaling (wie Python)
    const x = frequencies;
    const y = centroids;
    const z = loudness;
    
    const target_x_min = Math.min(...x);
    const target_x_max = Math.max(...x);
    const target_y_min = Math.min(...y);
    const target_y_max = Math.max(...y);
    const target_z_min = Math.min(...z);
    const target_z_max = Math.max(...z);
    
    x_min += (target_x_min - x_min) * SMOOTH_FACTOR;
    x_max += (target_x_max - x_max) * SMOOTH_FACTOR;
    y_min += (target_y_min - y_min) * SMOOTH_FACTOR;
    y_max += (target_y_max - y_max) * SMOOTH_FACTOR;
    z_min += (target_z_min - z_min) * SMOOTH_FACTOR;
    z_max += (target_z_max - z_max) * SMOOTH_FACTOR;
    
    // Skalierung auf Szene
    const scaleX = 1000 / Math.max(x_max - x_min, 1);
    const scaleY = 1000 / Math.max(y_max - y_min, 1);
    const scaleZ = 500 / Math.max(z_max - z_min, 0.01);
    
    // AGE / FADING EFFEKT (wie Python)
    for(let i=0; i<maxCapacity; i++){
      const p = i*3;
      const c = i*4;
      
      if(i < n){
        const age = i / Math.max(1, n-1);
        
        // Position (normalisiert und skaliert)
        positions[p]   = (x[i] - x_min) * scaleX - 500;
        positions[p+1] = (y[i] - y_min) * scaleY - 500;
        positions[p+2] = (z[i] - z_min) * scaleZ;
        
        // Farbe wie Python: age-basiertes Gr√ºn
        colors[c]   = age * 0.2;  // R (leicht gelb)
        colors[c+1] = age;         // G (Gr√ºn)
        colors[c+2] = 0;           // B
        colors[c+3] = age * 0.9;   // Alpha
        
        sizes[i] = 15;
        
      } else {
        positions[p] = positions[p+1] = positions[p+2] = 1e6;
        colors[c] = colors[c+1] = colors[c+2] = colors[c+3] = 0;
        sizes[i] = 0;
      }
    }
    
    geometry.attributes.position.needsUpdate = true;
    geometry.attributes.color.needsUpdate = true;
    geometry.attributes.size.needsUpdate = true;
    
    // Linien mit Age-Fading
    let lp = 0, lc = 0;
    for(let i=0; i<n-1; i++){
      const A = i*3, B = (i+1)*3;
      const age = i / Math.max(1, n-1);
      const alpha = age * 0.7;
      
      linePositions[lp++] = positions[A];
      linePositions[lp++] = positions[A+1];
      linePositions[lp++] = positions[A+2];
      linePositions[lp++] = positions[B];
      linePositions[lp++] = positions[B+1];
      linePositions[lp++] = positions[B+2];
      
      // Beide Endpunkte der Linie mit gleicher Farbe
      for(let j=0; j<2; j++){
        lineColors[lc++] = age * 0.2;
        lineColors[lc++] = age;
        lineColors[lc++] = 0;
        lineColors[lc++] = alpha;
      }
    }
    
    for(; lp<linePositions.length; lp++) linePositions[lp] = 1e6;
    for(; lc<lineColors.length; lc++) lineColors[lc] = 0;
    
    lineGeom.attributes.position.needsUpdate = true;
    lineGeom.attributes.color.needsUpdate = true;
    
    updateCoordinates();
  }
  
  renderer.render(scene, camera);
}

requestAnimationFrame(animate);

// ================================
// RESIZE
// ================================
window.addEventListener("resize", ()=>{
  camera.aspect = innerWidth/innerHeight;
  camera.updateProjectionMatrix();
  renderer.setSize(innerWidth, innerHeight);
});

console.log("‚úÖ TBFL_6 Visualizer bereit!");
console.log("üìä FFT Size:", FFT_SIZE);
console.log("üìç Max Points:", MAX_POINTS);
console.log("üîá Noise Threshold:", NOISE_THRESHOLD);

</script>

</body>
</html>
