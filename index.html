<!doctype html>
<html lang="de">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover" />
<title>TBFL_6 ‚Äî Web Audio Visualizer</title>

<!-- Three.js r128 - funktioniert garantiert -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>

<style>
  html,body { height:100%; margin:0; background:#000; color:#00FF00; font-family: monospace; overflow:hidden; }
  #ui {
    position: absolute; left:12px; top:12px; z-index: 10;
    background: rgba(0,0,0,0.7); border:1px solid #00ff00; padding:12px; border-radius:6px;
    box-shadow: 0 0 20px rgba(0,255,0,0.3);
  }
  button, label { 
    color:#00FF00; background:#001100; border:1px solid #00ff00; 
    padding:8px 12px; margin:4px; border-radius:4px; cursor:pointer; 
    font-family: monospace; font-size:12px;
    transition: all 0.2s;
  }
  button:hover, label:hover { background:#003300; box-shadow: 0 0 10px rgba(0,255,0,0.5); }
  button:active, label:active { transform: scale(0.95); }
  input[type=file] { display:none; }
  #title { font-weight:bold; font-size:16px; color:#00FF00; display:block; margin-bottom:8px; }
  #status { 
    font-size:11px; color:#88ff88; margin-top:8px; padding:6px; 
    background:rgba(0,50,0,0.3); border-radius:4px; min-height:20px;
  }
  .error { color:#ff0000 !important; }
  .success { color:#00ff00 !important; }
  canvas { display:block; }
</style>
</head>

<body>

<!-- UI -->
<div id="ui">
  <div id="title">üéµ TBFL_6 ‚Äî Audio Visualizer</div>
  <button id="btn-mic">üé§ Mikrofon starten</button>
  <label for="wavfile">üìÅ WAV laden</label>
  <input id="wavfile" type="file" accept=".wav,.mp3,audio/*" />
  <button id="btn-stop">‚èπ Stop</button>
  <div id="status">Bereit. Klicke auf Mikrofon oder lade eine Datei.</div>
</div>


<script>
console.log("üéµ TBFL_6 Visualizer wird initialisiert...");

// ============================================================================
// iOS / SAFARI AUDIO FIX
// ============================================================================
let audioCtx = null;

document.addEventListener("touchstart", () => {
  if (audioCtx && audioCtx.state === "suspended") {
    console.log("AudioContext wird aktiviert (iOS Touch)");
    audioCtx.resume();
  }
}, { once: true });


// ============================================================================
// THREE.JS SETUP
// ============================================================================
const scene = new THREE.Scene();
scene.background = new THREE.Color(0x000000);
scene.fog = new THREE.Fog(0x000000, 500, 2000);

const camera = new THREE.PerspectiveCamera(45, innerWidth/innerHeight, 0.1, 10000);
camera.position.set(0, 300, 800);

const renderer = new THREE.WebGLRenderer({antialias:true, alpha:true});
renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
renderer.setSize(innerWidth, innerHeight);
document.body.appendChild(renderer.domElement);

// Beleuchtung
const ambient = new THREE.AmbientLight(0x00ff00, 0.1);
scene.add(ambient);

const pointLight = new THREE.PointLight(0x00ff00, 0.5, 1500);
pointLight.position.set(0, 400, 0);
scene.add(pointLight);

// Grid
const gridHelper = new THREE.GridHelper(2000, 40, 0x00ff00, 0x003300);
gridHelper.material.opacity = 0.1;
gridHelper.material.transparent = true;
scene.add(gridHelper);


// ============================================================================
// AUDIO VARIABLES
// ============================================================================
let analyser = null;
let sourceNode = null;
let dataArray = null;
let freqBinCount = 0;
let running = false;
let audioSource = null; // Track f√ºr cleanup

const FFT_SIZE = 2048;
const NOISE_THRESHOLD = 0.002;

const maxPoints = 50;
const freqs = [];
const louds = [];
const cents = [];


// ============================================================================
// GEOMETRY (POINT CLOUD + LINES)
// ============================================================================
const maxCapacity = maxPoints;
const positions = new Float32Array(maxCapacity * 3);
const colors = new Float32Array(maxCapacity * 3);
const sizes = new Float32Array(maxCapacity);

const geometry = new THREE.BufferGeometry();
geometry.setAttribute("position", new THREE.BufferAttribute(positions, 3));
geometry.setAttribute("color", new THREE.BufferAttribute(colors, 3));
geometry.setAttribute("size", new THREE.BufferAttribute(sizes, 1));

const material = new THREE.ShaderMaterial({
  vertexColors: true,
  transparent: true,
  depthTest: true,
  uniforms: { pointScale: { value: window.innerHeight / 2 } },
  vertexShader: `
      attribute float size;
      varying vec3 vColor;
      void main(){
        vColor = color;
        vec4 mvPosition = modelViewMatrix * vec4(position,1.0);
        gl_Position = projectionMatrix * mvPosition;
        gl_PointSize = size * (300.0 / -mvPosition.z);
      }
    `,
  fragmentShader: `
      varying vec3 vColor;
      void main(){
        float dist = length(gl_PointCoord - vec2(0.5));
        if(dist > 0.5) discard;
        float alpha = 1.0 - (dist * 2.0);
        gl_FragColor = vec4(vColor, alpha);
      }
    `
});

const points = new THREE.Points(geometry, material);
scene.add(points);

// Linien zwischen Punkten
const linePositions = new Float32Array((maxCapacity - 1) * 2 * 3);
const lineGeom = new THREE.BufferGeometry();
lineGeom.setAttribute("position", new THREE.BufferAttribute(linePositions, 3));
const lineMat = new THREE.LineBasicMaterial({ color: 0x00ff00, transparent: true, opacity: 0.6 });
const lines = new THREE.LineSegments(lineGeom, lineMat);
scene.add(lines);


// ============================================================================
// HELPER FUNCTIONS
// ============================================================================
const FMIN = 20, FMAX = 22050;

function freqToX(f){
  const t = (Math.log10(Math.max(f,FMIN)) - Math.log10(FMIN)) / (Math.log10(FMAX) - Math.log10(FMIN));
  return (t - 0.5) * 1400;
}
function centroidToY(c){ return (c/2000)*800; }
function loudToZ(l){ return Math.min(Math.max(l*5,0.001),1.5); }

function computeRMS(arr){
  let s=0;
  for(let i=0;i<arr.length;i++) s+=arr[i]*arr[i];
  return Math.sqrt(s/arr.length);
}

function computeCentroid(mags, freq){
  let num=0, den=0;
  for(let i=0;i<mags.length;i++){
    num += mags[i]*freq[i];
    den += mags[i];
  }
  return den>0 ? num/den : 0;
}

function updateStatus(msg, type = 'normal'){
  const status = document.getElementById('status');
  status.textContent = msg;
  status.className = type;
  console.log(`[${type}] ${msg}`);
}


// ============================================================================
// AUDIO START (MIC)
// ============================================================================
async function startMic() {
  if (running) {
    updateStatus("Audio l√§uft bereits...", "error");
    return;
  }

  updateStatus("Mikrofon wird gestartet...", "normal");
  console.log("üé§ Mikrofon-Zugriff wird angefordert...");

  try {
    // AudioContext erstellen
    if (!audioCtx) {
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      console.log("‚úì AudioContext erstellt");
    }

    if (audioCtx.state === "suspended") {
      await audioCtx.resume();
      console.log("‚úì AudioContext aktiviert");
    }

    // Mikrofon-Stream anfordern
    const stream = await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: false,
        noiseSuppression: false,
        autoGainControl: false
      }
    });
    console.log("‚úì Mikrofon-Zugriff gew√§hrt");

    sourceNode = audioCtx.createMediaStreamSource(stream);
    analyser = audioCtx.createAnalyser();
    analyser.fftSize = FFT_SIZE;
    analyser.smoothingTimeConstant = 0.65;

    freqBinCount = analyser.frequencyBinCount;
    dataArray = new Float32Array(freqBinCount);

    sourceNode.connect(analyser);
    running = true;
    audioSource = stream;

    updateStatus("‚úì Mikrofon aktiv! Sprechen oder Musik abspielen.", "success");
    console.log("‚úì Visualizer l√§uft");

  } catch (err) {
    console.error("‚ùå Mikrofon-Fehler:", err);
    
    let errorMsg = "Mikrofon-Fehler: ";
    if (err.name === "NotAllowedError") {
      errorMsg += "Zugriff verweigert. Bitte erlaube Mikrofon-Zugriff in den Browser-Einstellungen.";
    } else if (err.name === "NotFoundError") {
      errorMsg += "Kein Mikrofon gefunden. Bitte Mikrofon anschlie√üen.";
    } else {
      errorMsg += err.message;
    }
    
    updateStatus(errorMsg, "error");
  }
}


// ============================================================================
// AUDIO: FILE
// ============================================================================
async function startFile(file){
  console.log("üìÅ Datei wird geladen:", file.name);
  
  if (running) stopAll();

  updateStatus(`Lade ${file.name}...`, "normal");

  try {
    if (!audioCtx) {
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    }

    const buf = await file.arrayBuffer();
    const decoded = await audioCtx.decodeAudioData(buf);
    console.log(`‚úì Audio dekodiert: ${decoded.duration.toFixed(2)}s, ${decoded.sampleRate}Hz`);

    const bs = audioCtx.createBufferSource();
    bs.buffer = decoded;

    analyser = audioCtx.createAnalyser();
    analyser.fftSize = FFT_SIZE;
    analyser.smoothingTimeConstant = 0.65;

    freqBinCount = analyser.frequencyBinCount;
    dataArray = new Float32Array(freqBinCount);

    bs.connect(analyser);
    analyser.connect(audioCtx.destination);

    bs.start();
    running = true;
    audioSource = bs;

    updateStatus(`‚úì Spiele ab: ${file.name}`, "success");

    bs.onended = () => {
      running = false;
      updateStatus("Wiedergabe beendet.", "normal");
      console.log("‚èπ Wiedergabe beendet");
    };

  } catch(err) {
    console.error("‚ùå Datei-Fehler:", err);
    updateStatus("Fehler beim Laden: " + err.message, "error");
  }
}


// ============================================================================
// STOP AUDIO
// ============================================================================
function stopAll(){
  console.log("‚èπ Audio wird gestoppt");
  running = false;
  
  // Stream stoppen
  if(audioSource && audioSource.getTracks){
    audioSource.getTracks().forEach(track => track.stop());
  }
  
  // Buffer Source stoppen
  if(audioSource && audioSource.stop){
    try{ audioSource.stop(); }catch(e){}
  }
  
  // Disconnect
  try{ 
    if(sourceNode) sourceNode.disconnect(); 
    if(analyser) analyser.disconnect();
  }catch(e){}
  
  analyser = sourceNode = audioSource = null;
  
  // Arrays leeren
  freqs.length = 0;
  louds.length = 0;
  cents.length = 0;
  
  updateStatus("Gestoppt. Bereit f√ºr neuen Input.", "normal");
}


// ============================================================================
// UI EVENTS
// ============================================================================
document.getElementById("btn-mic").onclick = () => {
  startMic().catch(err => {
    console.error("Fehler beim Starten:", err);
  });
};

document.getElementById("btn-stop").onclick = stopAll;

document.getElementById("wavfile").addEventListener("change", e => {
  if (e.target.files[0]) {
    startFile(e.target.files[0]);
  }
  e.target.value = ''; // Reset f√ºr erneutes Laden derselben Datei
});


// ============================================================================
// ANIMATION LOOP
// ============================================================================
let rot = 0;
let lastTime = performance.now();

function animate(t){
  requestAnimationFrame(animate);

  const dt = (t - lastTime)/1000;
  lastTime = t;

  // Kamera-Rotation
  rot += 0.3 * dt * 60;
  camera.position.x = Math.sin(rot*0.01)*800;
  camera.position.z = Math.cos(rot*0.01)*800;
  camera.lookAt(0,200,0);

  // Audio-Analyse
  if(running && analyser){
    const timeData = new Float32Array(analyser.fftSize);
    analyser.getFloatTimeDomainData(timeData);
    const rms = computeRMS(timeData);

    const freqDb = new Float32Array(freqBinCount);
    analyser.getFloatFrequencyData(freqDb);

    const mags = new Float32Array(freqBinCount);
    const binFreqs = new Float32Array(freqBinCount);

    const nyquist = audioCtx.sampleRate/2;
    for(let i=0;i<freqBinCount;i++){
      mags[i] = Math.pow(10, freqDb[i]/20);
      binFreqs[i] = (i/freqBinCount)*nyquist;
    }

    let maxIdx = 0;
    let maxVal = -Infinity;
    for(let i=0;i<mags.length;i++){
      if(mags[i] > maxVal){ maxVal=mags[i]; maxIdx=i; }
    }

    const peak = binFreqs[maxIdx] || 0;
    const centroid = computeCentroid(mags, binFreqs);

    if(rms >= NOISE_THRESHOLD){
      if(freqs.length >= maxPoints){ 
        freqs.shift(); 
        louds.shift(); 
        cents.shift(); 
      }
      freqs.push(peak);
      louds.push(rms);
      cents.push(centroid);
    }
  }

  // Geometrie aktualisieren
  const n = freqs.length;

  for(let i=0;i<maxCapacity;i++){
    const p = i*3;

    if(i < n){
      const x = freqToX(freqs[i]);
      const y = centroidToY(cents[i]);
      const z = loudToZ(louds[i]);

      positions[p]=x; positions[p+1]=y; positions[p+2]=z;

      const age = i / Math.max(1,n-1);
      colors[p] = age*0.3;
      colors[p+1] = 0.4 + age*0.6;
      colors[p+2] = 0;

      sizes[i] = 10 + louds[i]*20;

    } else {
      positions[p]=positions[p+1]=positions[p+2]=1e6;
      sizes[i]=0;
      colors[p]=colors[p+1]=colors[p+2]=0;
    }
  }

  geometry.attributes.position.needsUpdate = true;
  geometry.attributes.color.needsUpdate = true;
  geometry.attributes.size.needsUpdate = true;

  // Linien aktualisieren
  let lp=0;
  for(let i=0;i<n-1;i++){
    const A=i*3, B=(i+1)*3;
    linePositions[lp++] = positions[A];
    linePositions[lp++] = positions[A+1];
    linePositions[lp++] = positions[A+2];
    linePositions[lp++] = positions[B];
    linePositions[lp++] = positions[B+1];
    linePositions[lp++] = positions[B+2];
  }
  for(;lp<linePositions.length;lp++) linePositions[lp]=1e6;
  lineGeom.attributes.position.needsUpdate = true;

  // Licht-Animation
  pointLight.intensity = 0.5 + (n/maxPoints)*0.5;

  renderer.render(scene, camera);
}

requestAnimationFrame(animate);


// ============================================================================
// RESIZE
// ============================================================================
window.addEventListener("resize", ()=>{
  camera.aspect = innerWidth/innerHeight;
  camera.updateProjectionMatrix();
  renderer.setSize(innerWidth, innerHeight);
  console.log("üìê Fenster-Gr√∂√üe angepasst");
});

// ============================================================================
// INIT
// ============================================================================
console.log("‚úÖ TBFL_6 Visualizer bereit!");
console.log("üìä FFT Size:", FFT_SIZE);
console.log("üìç Max Points:", maxPoints);

</script>

</body>
</html>
